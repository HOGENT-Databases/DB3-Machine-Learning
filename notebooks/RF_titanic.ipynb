{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest classification with Scikit-Learn\n",
    "The process of fitting a decision tree to our data can be done in Scikit-Learn with the **DecisionTreeClassifier** estimator:\n",
    "  \n",
    "```python\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tree = DecisionTreeClassifier().fit(X, y)\n",
    "```\n",
    "However, as we have seen earlier, it’s better to **use Random Forest to reduce overfitting**. Applying the Random Forest classifier to the titanic data is very similar to Naïve Bayes.   \n",
    "  \n",
    "First we explore, transform and clean the data the same way as we did for Naïve Bayes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Braund, Mr. Owen Harris</td>\n      <td>male</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>A/5 21171</td>\n      <td>7.2500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n      <td>female</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>PC 17599</td>\n      <td>71.2833</td>\n      <td>C85</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n      <td>Heikkinen, Miss. Laina</td>\n      <td>female</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>STON/O2. 3101282</td>\n      <td>7.9250</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n      <td>female</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>113803</td>\n      <td>53.1000</td>\n      <td>C123</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Allen, Mr. William Henry</td>\n      <td>male</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>373450</td>\n      <td>8.0500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 56
    }
   ],
   "source": [
    "# import the library \n",
    "import pandas as pd\n",
    "url = 'https://raw.githubusercontent.com/HOGENT-Databases/DB3-Workshops/master/data/titanic.csv'\n",
    "titanic = pd.read_csv(url)\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "          PassengerId  Pclass  Name  Sex  Age  SibSp  Parch  Ticket  Fare  \\\n",
       "Survived                                                                    \n",
       "0                 549     549   549  549  424    549    549     549   549   \n",
       "1                 342     342   342  342  290    342    342     342   342   \n",
       "\n",
       "          Cabin  Embarked  \n",
       "Survived                   \n",
       "0            68       549  \n",
       "1           136       340  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n    </tr>\n    <tr>\n      <th>Survived</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>549</td>\n      <td>549</td>\n      <td>549</td>\n      <td>549</td>\n      <td>424</td>\n      <td>549</td>\n      <td>549</td>\n      <td>549</td>\n      <td>549</td>\n      <td>68</td>\n      <td>549</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>342</td>\n      <td>342</td>\n      <td>342</td>\n      <td>342</td>\n      <td>290</td>\n      <td>342</td>\n      <td>342</td>\n      <td>342</td>\n      <td>342</td>\n      <td>136</td>\n      <td>340</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 57
    }
   ],
   "source": [
    "# explore the data to estimate if we have enough (statistically relevant) data for both classes\n",
    "titanic.groupby('Survived').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Survived  Pclass     Sex   Age  SibSp  Parch\n",
       "0         0       3    male  22.0      1      0\n",
       "1         1       1  female  38.0      1      0\n",
       "2         1       3  female  26.0      0      0\n",
       "3         1       1  female  35.0      1      0\n",
       "4         0       3    male  35.0      0      0"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>3</td>\n      <td>male</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n      <td>female</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>3</td>\n      <td>female</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>1</td>\n      <td>female</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>3</td>\n      <td>male</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 58
    }
   ],
   "source": [
    "# We drop clearly irrelevant attributes. Pay attention for bias! Don't let your own opinion play. \n",
    "titanic = titanic.drop(['PassengerId','Name','Ticket','Fare','Cabin','Embarked'],axis=1)\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Before\nSurvived    891\nPclass      891\nSex         891\nAge         714\nSibSp       891\nParch       891\ndtype: int64\n\nAfter\nSurvived    714\nPclass      714\nSex         714\nAge         714\nSibSp       714\nParch       714\ndtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Before')\n",
    "print(titanic.count())\n",
    "print()\n",
    "\n",
    "# drop all lines that contain empty (null or NaN) values\n",
    "titanic = titanic.dropna()\n",
    "\n",
    "print('After')\n",
    "print(titanic.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "          Pclass  Sex  Age  SibSp  Parch\n",
       "Survived                                \n",
       "0            424  424  424    424    424\n",
       "1            290  290  290    290    290"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Pclass</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n    </tr>\n    <tr>\n      <th>Survived</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>424</td>\n      <td>424</td>\n      <td>424</td>\n      <td>424</td>\n      <td>424</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>290</td>\n      <td>290</td>\n      <td>290</td>\n      <td>290</td>\n      <td>290</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 60
    }
   ],
   "source": [
    "# see what remains\n",
    "titanic.groupby('Survived').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Survived  Pclass  Sex   Age  SibSp  Parch\n",
       "0         0       3    1  22.0      1      0\n",
       "1         1       1    2  38.0      1      0\n",
       "2         1       3    2  26.0      0      0\n",
       "3         1       1    2  35.0      1      0\n",
       "4         0       3    1  35.0      0      0"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>3</td>\n      <td>1</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>3</td>\n      <td>2</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>3</td>\n      <td>1</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 61
    }
   ],
   "source": [
    "import numpy as np\n",
    "titanic['Sex'] = np.where(titanic['Sex']>='male', 1, 2)\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = titanic.drop('Survived',axis=1)\n",
    "y = titanic['Survived']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to train the data using the RandomForestClassifier. Parameter n_estimators is the number of trees in the forest. Default = 10. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=300)"
      ]
     },
     "metadata": {},
     "execution_count": 63
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier(n_estimators=300)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test2 = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.8093023255813954"
      ]
     },
     "metadata": {},
     "execution_count": 65
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Optimal number of trees = 50\nAccuracy =  0.82\n"
     ]
    }
   ],
   "source": [
    "# We could also try to find the optimal number of trees in a automated way. \n",
    "\n",
    "best_accuracy = 0\n",
    "best_trees = 0\n",
    "\n",
    "for trees in range(50,550,50):\n",
    "    model = RandomForestClassifier(n_estimators=trees)\n",
    "    model.fit(X_train, y_train)    \n",
    "    y_test2 = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_test2)\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_trees = trees\n",
    "        \n",
    "print('Optimal number of trees = % s' %(best_trees))\n",
    "print('Accuracy = % 3.2f' % (best_accuracy)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above approach involves a certain risk of _\"leaking\"_ the test data to the tuning of the algorithm. Indeed, we are in fact searching for the optimal hyperparameters (i.e. the number of trees) by using the same (randomly determined) test set in every iteration. This means we are tuning the classifier for a specific version of the test set instead of for the problem in general. A better approach would be to use a training, a validation and a test set and use the validation set for hyperparameter tuning and only use the test set to determine the accuracy after these tuning. Therefore, in the next cell, we further split the training data in a training and a validation set. To obtain maximum randomization we repeat this random split for each number of trees. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Optimal number of trees = 200\nAccuracy on validation set =  0.85\nAccuracy on test set =  0.78\n"
     ]
    }
   ],
   "source": [
    "X_remainder, X_test, y_remainder, y_test = train_test_split(X,y,test_size=0.30)\n",
    "\n",
    "best_accuracy = 0\n",
    "best_trees = 0\n",
    "\n",
    "for trees in range(50,550,50):\n",
    "    X_train, X_validation, y_train, y_validation = train_test_split(X_remainder,y_remainder,test_size=0.30)\n",
    "    model = RandomForestClassifier(n_estimators=trees)\n",
    "    model.fit(X_train, y_train)    \n",
    "    y_validation2 = model.predict(X_validation)\n",
    "    accuracy = accuracy_score(y_validation, y_validation2)\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_trees = trees\n",
    "        best_validation = model.predict(X_test)\n",
    "        \n",
    "print('Optimal number of trees = % s' %(best_trees))\n",
    "print('Accuracy on validation set = % 3.2f' % (best_accuracy)) \n",
    "accuracyOnTestSet = accuracy_score(y_test, best_validation)\n",
    "print('Accuracy on test set = % 3.2f' % (accuracyOnTestSet))"
   ]
  },
  {
   "source": [
    "It  turns out that the accuracy of the Random Forest classifier is very close to Naïve Bayes. However, Decision Tree and Random Forest classifiers have one major advantage over Naïve Bayes: you can **determine the relative importance of each feature**.  \n",
    "  \n",
    "From an ethical point of view this is also a very important feature if you have to declare why a model makes a certain decision, for instance in case of deciding to grant a loan to a bank customer."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Index(['Pclass', 'Sex', 'Age', 'SibSp', 'Parch'], dtype='object')\n[0.16389414 0.26973187 0.43242171 0.06725788 0.06669439]\n"
     ]
    }
   ],
   "source": [
    "print(X_train.columns)\n",
    "print(model.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        Importance\n",
       "Age       0.432422\n",
       "Sex       0.269732\n",
       "Pclass    0.163894\n",
       "SibSp     0.067258\n",
       "Parch     0.066694"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Importance</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Age</th>\n      <td>0.432422</td>\n    </tr>\n    <tr>\n      <th>Sex</th>\n      <td>0.269732</td>\n    </tr>\n    <tr>\n      <th>Pclass</th>\n      <td>0.163894</td>\n    </tr>\n    <tr>\n      <th>SibSp</th>\n      <td>0.067258</td>\n    </tr>\n    <tr>\n      <th>Parch</th>\n      <td>0.066694</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 69
    }
   ],
   "source": [
    "# we now combine those two collections into a dataframe\n",
    "pd.DataFrame(model.feature_importances_,columns=['Importance'],index=X_train.columns).sort_values(by='Importance',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We learn from this that by far the three most important criteria to survive the Titanic disaster were: (1) Age, (2) Sex and (3) Ticket class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.6375\n"
     ]
    }
   ],
   "source": [
    "# Determine the false negative rate: what's the proportion of the passengers \n",
    "# who survived that we declared death. \n",
    "results = pd.DataFrame({'true':y_test,'estimated':y_test2})\n",
    "\n",
    "results['TP'] = np.where((results['true'] == 1) & (results['estimated'] == 1),1,0)\n",
    "results['TN'] = np.where((results['true'] == 0) & (results['estimated'] == 0),1,0)\n",
    "results['FP'] = np.where((results['true'] == 0) & (results['estimated'] == 1),1,0)\n",
    "results['FN'] = np.where((results['true'] == 1) & (results['estimated'] == 0),1,0)\n",
    "\n",
    "FNrate = results['FN'].sum()/(results['FN'].sum() + results['TP'].sum())\n",
    "print(FNrate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One hot encoding for categorical features\n",
    "One common type of non-numerical data is categorical data. For example, in the previous example, Sex = male or female. \n",
    "\n",
    "We encode male as 1 and female as 2 because the algorithms we used only work with numerical features. \n",
    "However, Scikit-Learn models make the fundamental assumption that numerical features reflect algebraic quantities, \n",
    "so in our example they would assume that a female is twice a male, which does not make much sense. \n",
    "In this case, one proven technique is to use one-hot encoding, which effectively creates extra columns indicating \n",
    "the presence or absence of a category with a value of 1 or 0 respectively. \n",
    "This has the benefit of not weighting a value improperly but does have the downside of adding more columns to the data set. \n",
    "Pandas supports this feature using the function _get_dummies_. This function is named this way because it creates \n",
    "dummy/indicator variables (aka 1 or 0).  \n",
    "  \n",
    "In our example we can then replace the line\n",
    "```python\n",
    "titanic['Sex'] = np.where(titanic['Sex']>='male', 1, 2)\n",
    "```\n",
    "by\n",
    "```python\n",
    "titanic = pd.get_dummies(titanic, columns=[\"Sex\"], prefix=[\"Sex\"])\n",
    "```\n",
    "Of course, you can also use one hot encoding for 'numerical' features that are categorical by nature. For example, if in the original titanic data the gender would have been encoded as 1 or 2.  \n",
    "  \n",
    "Let's now redo the modeling using one-hot-encoding for Sex. For brevity we don't search for the optimal number of trees, be use what we have found above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "   Survived  Pclass   Age  SibSp  Parch  Sex_female  Sex_male\n0         0       3  22.0      1      0           0         1\n1         1       1  38.0      1      0           1         0\n2         1       3  26.0      0      0           1         0\n3         1       1  35.0      1      0           1         0\n4         0       3  35.0      0      0           0         1\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.7953488372093023"
      ]
     },
     "metadata": {},
     "execution_count": 71
    }
   ],
   "source": [
    "url = 'https://raw.githubusercontent.com/HOGENT-Databases/DB3-Workshops/master/data/titanic.csv'\n",
    "titanic = pd.read_csv(url)\n",
    "titanic = titanic.drop(['PassengerId','Name','Ticket','Fare','Cabin','Embarked'],axis=1)\n",
    "titanic = titanic.dropna()\n",
    "titanic = pd.get_dummies(titanic, columns=[\"Sex\"], prefix=[\"Sex\"])\n",
    "print(titanic.head())\n",
    "X = titanic.drop('Survived',axis=1)\n",
    "y = titanic['Survived']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.30)\n",
    "model = RandomForestClassifier(n_estimators=best_trees) # ues the optimal number of trees we have found above\n",
    "model.fit(X_train, y_train)\n",
    "y_test2 = model.predict(X_test)\n",
    "accuracy_score(y_test, y_test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this specific case one-hot-encoding is not offering an advantage but in general this is a better approach. \n",
    "A disadvantage of splitting the columns is that the relative importances are also split: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        index  Importance\n",
       "0         Age    0.407596\n",
       "1    Sex_male    0.194067\n",
       "2  Sex_female    0.153117\n",
       "3      Pclass    0.142342\n",
       "4       SibSp    0.054395\n",
       "5       Parch    0.048482"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>Importance</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Age</td>\n      <td>0.407596</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Sex_male</td>\n      <td>0.194067</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Sex_female</td>\n      <td>0.153117</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Pclass</td>\n      <td>0.142342</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>SibSp</td>\n      <td>0.054395</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Parch</td>\n      <td>0.048482</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 72
    }
   ],
   "source": [
    "importances = pd.DataFrame(model.feature_importances_,columns=['Importance'],index=X_train.columns).sort_values(by='Importance',ascending=False).reset_index()\n",
    "importances\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   level_0   index  Importance\n",
       "0        0     Age    0.407596\n",
       "1        3     Sex    0.347185\n",
       "2        2  Pclass    0.142342\n",
       "3        4   SibSp    0.054395\n",
       "4        1   Parch    0.048482"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>level_0</th>\n      <th>index</th>\n      <th>Importance</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>Age</td>\n      <td>0.407596</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3</td>\n      <td>Sex</td>\n      <td>0.347185</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>Pclass</td>\n      <td>0.142342</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>SibSp</td>\n      <td>0.054395</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>Parch</td>\n      <td>0.048482</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 73
    }
   ],
   "source": [
    "# We can group these relative importances together and make the sum of there values: \n",
    "importances['index'] = np.where(importances['index'].str.startswith ('Sex'),'Sex',importances['index'])\n",
    "imp = importances.groupby(['index'])['Importance'].sum().reset_index().sort_values(by='Importance',ascending=False).reset_index()\n",
    "imp"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}