{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Convolutional Neural Networks   \n",
    "When classifying images with (simple) feed forward neural networks we noticed that, due to the __linearizing__, we ignore typical image features like shapes or edges. To cope with this more advanced neural networks are often used in computer vision applications. In this section we discuss convolutional neural networks, also called convnets or CNNs. They’re also used in non-vision applications, such as NLP, recommender systems and much more. \n",
    "  \n",
    "The concept of convolution is based on the observation that images are rather stationary, which means they have a lot of repeating patches.  \n",
    "![](images/cnnbird.png)\n",
    "So instead of focusing on the entire image, which would be very compute intensive, we can better focus on patch levels. This is accomplished by convolving (Nederlands = rollen) a patch over the image resulting in a filtered image with a reduced dimension. That patch (or kernel) is a small area (typical a 3 x 3 square) that shifts over the original image from left to right and from top to bottom and that performs a simple arithmetic operation with the corresponding square in the image.  \n",
    "  \n",
    "Let’s examine convolution on a 6x6 image (Deitel & Deitel, 2019). Consider the following diagram in which the 3x3 shaded square represents the kernel – the numbers are simply position numbers showing the order in which the kernels are visited and processed. \n",
    "![](images/cnnlayer.png) \n",
    "You can think of the kernel as a __sliding window__ that the convolution layer moves one pixel at a time left-to-right across the image. When the kernel reaches the right edge, the convolution layer moves the kernel one pixel down and repeats the left-to-right process.  \n",
    "  \n",
    "The convolution layer performs mathematical calculations using those nine features to “learn” about them, then outputs __one new feature__ to position 1 in the layer’s output. An example of such a kernel and the calculations is shown below. \n",
    "![](images/cnnkernel.png)\n",
    "In the above example the value in the upper left corner of the output feature map is calculated as:  \n",
    "\\begin{equation}  \n",
    "(0 * 0) + (0 * 0) + (1 * 1) + (0 *1) + (1 * 0) + (0 * 1) + (1 * 1) + (0 * 1) + (1 * 1) = 3\n",
    "\\end{equation}\n",
    "  \n",
    "The kernel values are chosen by Keras based on best-practices.  \n",
    "  \n",
    "By looking at features near one another, the network begins to recognize features like edges, straight lines and curves. This might look like magic but it turns out that applying several convolutional layers results in learning essential features of the original image like in the examples below. \n",
    "![](images/cnnresults.png)   \n",
    "  \n",
    "Next, the convolution layer moves the kernel one pixel to the right (known as the stride) to position 2 in the output layer. This new position overlaps with two of the three columns in the previous position, so that the convolution layer can learn from all the features that touch one another. The layer learns from the nine features in the kernel in position 2 and outputs one new feature in position 2 of the output, as in:\n",
    "![](images/cnnlayer2.png)   \n",
    "The complete pass of the image left-to-right and top-to-bottom is called a __filter__. For a 3x3 kernel, the filter dimensions (4x4 in our sample above), will be two less than the input dimensions (6x6). In the case of the MNIST digits for each 28x28 MNIST image, the filter will be 26x26.  \n",
    "  \n",
    "The number of filters in the convolutional layer is commonly 32 or 64 when processing small images like those in MNIST, and each filter produces different results, since each kernel has 0’s and 1’s in different positions. The number of filters depends on the image dimensions – higher-resolution images have more features, so they require more filters. The set of filters produced by a convolution layer is called a __feature map__.  \n",
    "  \n",
    "Subsequent convolution layers combine features from previous feature maps to recognize larger features and so on. If we were doing facial recognition, early layers might recognize lines, edges, and curves, and subsequent layers might begin combining those into larger features like eyes, eyebrows, noses, ears and mouths. Once a network learns a feature because of convolution, it can recognize that feature anywhere in the image. This is one of the reasons that convnets are used for object recognition in images.  \n",
    "    \n",
    "We will now apply these concepts to the MNIST dataset we have used before. \n",
    "\n",
    "* **60,000** labeled digit image samples for **training**, **10,000** for testing\n",
    "* **28-by-28 pixel images** (**784 features**), represented as **NumPy arrays**\n",
    "* **Grayscale pixel intensity** (shade) values **0-255** \n",
    "* **Convnet** will perform [**probabilistic classification**](https://en.wikipedia.org/wiki/Probabilistic_classification)\n",
    "\t* Model will output **10 probabilities** indicating likelihood a digit is **0-9**\n",
    "\t* **Highest probability** is the **predicted value**\n",
    "\n",
    "### Loading and exploring the MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jcor864\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\jcor864\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\jcor864\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\jcor864\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\jcor864\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\jcor864\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "(10000, 28, 28)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "print(X_train.shape)\n",
    "\n",
    "print(y_train.shape)\n",
    "\n",
    "print(X_test.shape)\n",
    "\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### Data Preparation\n",
    "* MNIST dataset **requires some preparation** for use in a Keras convnet\n",
    "\n",
    "#### Reshaping the Image Data \n",
    "* **Keras convnets** require **NumPy array inputs** \n",
    "* Each **sample** must have the **shape**\n",
    "> (**width**, **height**, **channels**)\n",
    "* Each pixel has **one channel** (grayscale shade 0-255), so sample shapes will be \n",
    "> **`(28, 28, 1)`**\n",
    "* As the **neural network learns** from the images, it **creates many more channels**\n",
    "    * These channels will **represent more complex features**, like **edges**, **curves** and **lines**\n",
    "    * Enable network to **recognize digits** based on these features and how they’re **combined**  \n",
    "  \n",
    "* NumPy array method `reshape` receives a tuple representing the new shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train.reshape((60000, 28, 28, 1)) \n",
    "\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28, 1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = X_test.reshape((10000, 28, 28, 1))\n",
    "\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### Normalizing the Image Data \n",
    "* **Numeric feature values** may vary widely\n",
    "* Deep learning networks **perform better** on data that's **normalized** into\n",
    "    * the range **0.0-1.0**, or \n",
    "    * a range for which the data’s **mean is 0.0** and its **standard deviation is 1.0**\n",
    "        * S. Ioffe and Szegedy, C., “Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift.” https://arxiv.org/abs/1502.03167\n",
    "* Divide **each pixel** value by **255** to normalize into the range **0.0-1.0**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32') / 255\n",
    "\n",
    "X_test = X_test.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### One-Hot Encoding: Convert Labels to Categorical Data \n",
    "* **Predictions** for each digit will be an **array of 10 probabilities** \n",
    "* To **evaluate model accuracy**, Keras **compares predictions to dataset's labels**\n",
    "    * Both must have the **same shape**\n",
    "    * MNIST labels are **individual integers 0-9**\n",
    "* Must **transform labels** into **categorical data arrays** matching the **prediction format**\n",
    "* Use [**one-hot encoding**](https://en.wikipedia.org/wiki/One-hot) to convert labels from integers into 10-element **arrays of 1.0s and 0.0s** \n",
    "    * **only one element is 1.0** and the **rest are 0.0s**\n",
    "* Categorical representation of a **7**\n",
    "> <pre>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, <strong>1.0</strong>, 0.0, 0.0]</pre>\n",
    "* **`tensorflow.keras.utils`** function **`to_categorical`** performs **one-hot encoding**\n",
    "* Transform **`y_train`** and **`y_test`** into **two-dimensional arrays of categorical data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 10)\n",
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "\n",
    "print(y_train.shape)\n",
    "\n",
    "print(y_train[0])  # one sample’s categorical data\n",
    "\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Creating the Neural Network\n",
    "* Configure a **convolutional neural network**\n",
    "* **`Sequential` model** stacks layers to **execute sequentially**\n",
    "    * **output** of one layer becomes **input** to the next\n",
    "    * **Feed-forward network**\n",
    "    * Later, you’ll see that not all layers feed output to the next layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential \n",
    "\n",
    "cnn = Sequential() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### Adding Layers to the Network\n",
    "* A typical **convnet** consists of \n",
    "\t* **input layer** that receives **training samples**\n",
    "\t* **hidden layers** that **learn** from training samples\n",
    "\t* **output layer** that **produces predictions**\n",
    "* Import layer classes for a basic **convnet**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D, Dense, Flatten, MaxPooling2D "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution\n",
    "* We'll start with a **convolution layer**\n",
    "* Uses the **relationships between pixels in close proximity** to learn useful **features** (or patterns) in small areas of each sample\n",
    "* These **features** become **inputs** to **subsequent layers**   \n",
    "  \n",
    "* [**Kernels typically are 3-by-3**](https://www.quora.com/How-can-I-decide-the-kernel-size-output-maps-and-layers-of-CNN)\n",
    "    * We found convnets that used **5-by-5** and **7-by-7** \n",
    "    * Kernel-size is a **hyperparameter**\n",
    "* By looking at **features near one another**, the network begins to **recognize features** \n",
    "    * Like **edges**, **straight lines** and **curves**  \n",
    "    \n",
    "* Next, **convolution layer** moves **kernel one pixel to the right** (the **stride**) \n",
    "* **Overlaps** with previous kernel, so **convolution layer can learn** from all **features that touch one another**\n",
    "* **Complete pass** left-to-right and top-to-bottom is called a **filter**\n",
    "* For a **3-by-3 kernel**, the filter dimensions will be **two less than the input dimensions**\n",
    "    * For each 28-by-28 MNIST image, the filter will be 26-by-26 \n",
    "* **Number of filters** in the **convolutional layer** is commonly **32** or **64** for small images\n",
    "* Each filter produces different results\n",
    "* **Higher-resolution images** have **more features**, so they **require more filters**   \n",
    "* **Set of filters** produced by a **convolution layer** is called a **feature map**\n",
    "\n",
    "### Adding a Convolution Layer\n",
    "* **`Conv2D`** implements the convolution layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\jcor864\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "cnn.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu', \n",
    "               input_shape=(28, 28, 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **`filters=64`**—The number of **filters** in the resulting **feature map**.\n",
    "* **`kernel_size=(3, 3)`**—The **size of the kernel** used in each **filter**\n",
    "* **`activation='relu'`**—**Rectified Linear Unit activation function** is used to produce this layer’s output\n",
    "    * **Most widely used activation function** (Chollet, François. _Deep Learning with Python_. p. 72. Shelter Island, NY: Manning Publications, 2018)\n",
    "    * [**Good for performance** because it’s **easy to calculate**](https://towardsdatascience.com/exploring-activation-functions-for-neural-networks-73498da59b02) \n",
    "    * [Commonly recommended for **convolutional layers**](https://www.quora.com/How-should-I-choose-a-proper-activation-function-for-the-neural-network)   \n",
    "  \n",
    "* **First layer** in the model, so we specify the shape of each sample with `input_shape=(28, 28,1)` \n",
    "\t* Creates an **input layer** to **load the samples** and pass them into the **`Conv2D` layer**, which is actually the **first hidden layer**\n",
    "* Each subsequent layer **infers `input_shape`** from previous layer’s **output shape**\n",
    "    * Makes it easy to **stack** layers\n",
    "\n",
    "### Dimensionality of the First Convolution Layer’s Output\n",
    "* Input samples are 28-by-28-by-1—that is, **784 features each**\n",
    "* Specified **64 filters** and a **3-by-3 kernel** for the layer, so the **feature map size is 26-by-26-by-64** for a total of **43,264 features** \n",
    "\t* **Significant increase in dimensionality** \n",
    "    * **Enormous** compared to numbers of features processed in our Machine Learning examples\n",
    "* As each layer adds features, feature map **dimensionality** grows significantly\n",
    "    * This is one of reasons **deep learning** often requires **tremendous processing power**\n",
    "\n",
    "### Overfitting \n",
    "* Can occur when a **model is too complex** compared to what it is modeling\n",
    "* **Most extreme case**: Model **memorizes** its training data's features\n",
    "* **Overfitting** tends to occur in **deep learning** as the **dimensionality** becomes **too large** [\\[1\\]](https://cs231n.github.io/convolutional-networks/),[\\[2\\]](https://medium.com/@cxu24/why-dimensionality-reduction-is-important-dd60b5611543),[\\[3\\]](https://towardsdatascience.com/preventing-deep-neural-network-from-overfitting-953458db800a)\n",
    "* **Higher dimensionality** also increases (and sometimes explodes) **computation time**\n",
    "* For deep learning on **CPUs**, training could become **intolerably slow**\n",
    "* There are various techniques to **prevent overfitting** [\\[1\\]](https://towardsdatascience.com/deep-learning-3-more-on-cnns-handling-overfitting-2bd5d99abe5d), [\\[2\\]](https://www.kdnuggets.com/2015/04/preventing-overfitting-neural-networks.html) &mdash; we'll use **pooling**\n",
    "\n",
    "### Adding a Pooling Layer \n",
    "* To **reduce overfitting** and **computation time**, a **convolution layer** is often followed by one or more layers that **reduce dimensionality** of **convolution layer’s output**\n",
    "* **Pooling compresses** (or **down-samples**) the results by **discarding features**\n",
    "    * Helps make the model **more general**\n",
    "* **Most common pooling technique** is called **max pooling**\n",
    "\t* Examines a 2-by-2 square of features and keeps only the maximum feature.\n",
    "\n",
    "### Adding a Pooling Layer (cont.)\n",
    "* 2-by-2 blue square in position 1 represents the initial pool of features to examine:\n",
    "\n",
    "![Max pooling diagram showing the 6-by-6 set of numeric values we wish to compress with the 2-by-2 blue square in position 1 representing the initial pool of features to examine, and the 3-by-3 square representing the results of max pooling](images/pooling.png \"Max pooling diagram showing the 6-by-6 set of numeric values we wish to compress with the 2-by-2 blue square in position 1 representing the initial pool of features to examine, and the 3-by-3 square representing the results of max pooling\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Outputs **maximum feature** from each pool\n",
    "* Unlike convolution **pools do not overlap** \n",
    "* **Stride** for a 2-by-2 pool is **2**\n",
    "* Every group of four features is reduced to one, so 2-by-2 pooling **compresses** number of features by **75%**\n",
    "* Reduces previous layer’s output from **26-by-26-by-64** to **13-by-13-by-64**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(MaxPooling2D(pool_size=(2, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### Adding Another Convolutional Layer and Pooling Layer\n",
    "* **Convnets** often have **many convolution and pooling layers**. \n",
    "* [Keras team’s convnets](https://github.com/keras-team/keras-applications/tree/master/keras_applications) tend to **double** the number of **filters** in subsequent **convolutional layers** to enable the models to learn more relationships between the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu'))\n",
    "\n",
    "cnn.add(MaxPooling2D(pool_size=(2, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "* **Input** to the **second convolution layer** is the 13-by-13-by-64 **output of the first pooling layer**\n",
    "* **Output** of this **Conv2D layer** will be **11-by-11-by-128**\n",
    "* For **odd dimensions** like 11-by-11, **Keras pooling layers round down** by default (in this case to 10-by-10), so this pooling layer’s **output** will be **5-by-5-by-128**\n",
    "\n",
    "### Flattening the Results\n",
    "* Model's **final output** will be a **one-dimensional** array of 10 probabilities that classify the digits\n",
    "* To prepare for **one-dimensional final predictions**, need to **flatten** the previous layer’s output to **one dimension**\n",
    "* **`Flatten`** layer's output will be **1-by-3200** (5 &#215; 5 &#215; 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(Flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### Adding a Dense Layer to Reduce the Number of Features\n",
    "* Layers before the **`Flatten`** layer **learned digit features**\n",
    "* Now must **learn the relationships among those features** to **classify** which digit each image represents\n",
    "* Accomplished with **fully connected `Dense` layers**\n",
    "* The following **`Dense` layer** creates **128 neurons (`units`)** that **learn** from the 3200 outputs of the previous layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(Dense(units=128, activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "* Many **convnets** contain **at least one `Dense` layer** \n",
    "* **Convnets** geared to more complex image datasets with higher-resolution images like [**ImageNet**](http://www.image-net.org)—a dataset of over 14 million images—often have **several `Dense` layers**, commonly with **4096 neurons**\n",
    "* See the [Keras pretrained ImageNet convnets' code](https://github.com/keras-team/keras-applications/tree/master/keras_applications)\n",
    "\n",
    "### Adding Another Dense Layer to Produce the Final Output\n",
    "* Final **`Dense`** layer **classifies** inputs into **neurons** representing the classes **0-9**\n",
    "* The **`softmax` activation function** converts values of these 10 neurons into **classification probabilities**\n",
    "* **Neuron** with **highest probability** represents the **prediction** for a given digit image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(Dense(units=10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### Printing the Model’s Summary \n",
    "* Use model’s **`summary`** method\n",
    "* Note layers' **output shapes** and **numbers of parameters**\n",
    "* **Parameters** are the **weights** that the network **learns** during training [\\[1\\]](https://hackernoon.com/everything-you-need-to-know-about-neural-networks-8988c3ee4491),[\\[2\\]](https://www.kdnuggets.com/2018/06/deep-learning-best-practices-weight-initialization.html) \n",
    "* **Relatively small network**, but needs to **learn nearly 500,000 parameters**! \n",
    "\t* This is for **tiny images** that are less than 1/4 the size of icons on smartphone home screens\n",
    "\t* Imagine how many features a network would have to learn to process high-resolution 4K video frames or the super-high-resolution images produced by today’s digital cameras \n",
    "* In the **`Output Shape`** column, **`None`** means the model does not know in advance how many training samples you’re going to provide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 64)        640       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 3200)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               409728    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 485,514\n",
      "Trainable params: 485,514\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### Compiling the Model \n",
    "* Complete the model by calling its **`compile` method**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.compile(optimizer='adam',\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **`optimizer='adam'`**—The **optimizer** this model uses to **adjust the weights** throughout the neural network **as it learns**\n",
    "\t* [**Keras optimizers**](https://keras.io/optimizers/)\n",
    "\t* `'adam'` performs well across a wide variety of models [\\[1\\]](https://medium.com/octavian-ai/which-optimizer-and-learning-rate-should-i-use-for-deep-learning-5acb418f9b2),[\\[2\\]](https://towardsdatascience.com/types-of-optimization-algorithms-used-in-neural-networks-and-ways-to-optimize-gradient-95ae5d39529f)   \n",
    "   \n",
    "* **`loss='categorical_crossentropy'`**—The **loss function** used by the optimizer in **multi-classification networks** (ours predicts 10 classes)\n",
    "\t* **Optimizer** attempts to **minimize the values returned by the loss function** \n",
    "\t* For **binary classification**, Keras provides **`'binary_crossentropy'`**, and for **regression**, **`'mean_squared_error'`**\n",
    "\t* [Other loss functions](https://keras.io/losses/)\n",
    "\n",
    "* **`metrics=['accuracy']`**—List of **metrics** the network will produce to help you **evaluate the model**\n",
    "\t* **Accuracy** commonly used in **classification models**\n",
    "\t* We’ll use it to check **percentage of correct predictions**\n",
    "\t* [Other metrics](https://keras.io/metrics/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Training and Evaluating the Model \n",
    "* **Train a Keras model** by calling its **`fit` method**\n",
    "```python\n",
    "cnn.fit(X_train, y_train, epochs=5, batch_size=64, validation_split=0.1)\n",
    "```\n",
    "* **`epochs=5`**&mdash;train neural networks iteratively over time\n",
    "    * Each **`epoch`** processes **every training dataset sample** once\n",
    "    * **Hyperparameter** that may need tuning\n",
    "* **`batch_size=64`**&mdash;**number of samples to process at a time**\n",
    "    * Most models specify a **power of 2 from 32 to 512**\n",
    "* [**`validation_split=0.1`**&mdash;model should reserve the **last** 10% of the training samples for validation](https://keras.io/getting-started/faq/#how-is-the-validation-split-computed) \n",
    "\t* After each **epoch**, model uses validation samples to **make predictions** and display the **validation loss and accuracy** \n",
    "    * Use **tune your layers** and the **`fit` method’s hyperparameters**, or possibly change the **layer composition** of your model\n",
    "    * Can specify **separate validation data** with **`validation_data` argument** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54000 samples, validate on 6000 samples\n",
      "WARNING:tensorflow:From C:\\Users\\jcor864\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/5\n",
      "54000/54000 [==============================] - 95s 2ms/sample - loss: 0.1489 - acc: 0.9536 - val_loss: 0.0454 - val_acc: 0.9858\n",
      "Epoch 2/5\n",
      "54000/54000 [==============================] - 92s 2ms/sample - loss: 0.0431 - acc: 0.9868 - val_loss: 0.0375 - val_acc: 0.9882\n",
      "Epoch 3/5\n",
      "54000/54000 [==============================] - 90s 2ms/sample - loss: 0.0304 - acc: 0.9907 - val_loss: 0.0326 - val_acc: 0.9902\n",
      "Epoch 4/5\n",
      "54000/54000 [==============================] - 97s 2ms/sample - loss: 0.0218 - acc: 0.9930 - val_loss: 0.0310 - val_acc: 0.9908\n",
      "Epoch 5/5\n",
      "54000/54000 [==============================] - 95s 2ms/sample - loss: 0.0142 - acc: 0.9956 - val_loss: 0.0351 - val_acc: 0.9915\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x23e80b10dc8>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.fit(X_train, y_train, epochs=5, batch_size=64, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* As training proceeds, **`fit`** shows the **progress** of each **epoch**, **how long** the epoch took to execute, and the **evaluation metrics** for that epoch\n",
    "* Impressive **training accuracy (`acc`**) and **validation accurracy (`acc`)**, given that **we have not yet tried to tune the hyperparameters** or **tweak the number and types of the layers**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the Model on Unseen Data with Model’s **`evaluate` Method**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 6s 560us/sample - loss: 0.0349 - acc: 0.9896s - lo\n",
      "0.034876395662462166\n",
      "0.9896\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = cnn.evaluate(X_test, y_test)\n",
    "print(loss)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Without tuning, our **convnet model** is **+/-99% accurate** for **unseen data samples**\n",
    "    * Can find models online that predict MNIST with even **higher accuracy**\n",
    "    * **Experiment** with different numbers of layers, types of layers and layer parameters and observe how those changes affect your results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making Predictions with the Model’s **`predict` Method** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = cnn.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The first digit should be a 7 (shown as `1.` at index 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Check the **probabilities** returned by **`predict`** for **first test sample**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 0.0000000057%\n",
      "1: 0.0000000018%\n",
      "2: 0.0000003320%\n",
      "3: 0.0000000329%\n",
      "4: 0.0000000000%\n",
      "5: 0.0000000000%\n",
      "6: 0.0000000000%\n",
      "7: 100.0000000000%\n",
      "8: 0.0000000001%\n",
      "9: 0.0000000658%\n"
     ]
    }
   ],
   "source": [
    "for index, probability in enumerate(predictions[0]):\n",
    "    print(f'{index}: {probability:.10%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Our model believes this digit is a 7 with **nearly** 100% certainty\n",
    "* Not all predictions have this level of certainty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Locating the Incorrect Predictions \n",
    "* View some **incorrectly predicted images** to get a sense of digits **our model has trouble with**\n",
    "\t* If the model always mispredicts 8s, perhaps we need more 8s in our training data\n",
    "* To determine whether a prediction was correct, compare the index of the largest probability in `predictions[0]` to the index of the element containing **`1.0` in `y_test[0]`**\n",
    "\t* If **indices** are the same, **prediction was correct**\n",
    "* **Reshape the samples** from the shape `(28, 28, 1)` that Keras required for learning back to `(28, 28)`, which **Matplotlib requires to display the images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Locating the Incorrect Predictions\n",
    "images = X_test.reshape((10000, 28, 28))\n",
    "\n",
    "incorrect_predicted_images = []\n",
    "predicted_digits = []\n",
    "expected_digits = []\n",
    "\n",
    "for i, (p, e) in enumerate(zip(predictions, y_test)):\n",
    "    predicted, expected = np.argmax(p), np.argmax(e)\n",
    "\n",
    "    if predicted != expected:  # prediction was incorrect\n",
    "        incorrect_predicted_images.append(images[i])\n",
    "        predicted_digits.append(predicted)\n",
    "        expected_digits.append(expected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "104"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(incorrect_predicted_images)  # number of incorrect predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Incorrect Predictions\n",
    "* **Display 24 of the incorrect images** labeled with each image’s index, predicted value (`p`) and expected value (`e`)\n",
    "* Before reading the **expected values**, look at each digit and write down what digit you think it is\n",
    "* This is an important part of **getting to know your data**\n",
    "<!--![24 incorrectly predicted digit images](./ch15images/incorrect24.png \"24 incorrectly predicted digit images\")-->\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x864 with 24 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.figure()\n",
    "nrows,ncols=4,6\n",
    "plt.subplots(nrows,ncols, figsize=(16, 12))\n",
    "\n",
    "for i in range(nrows*ncols):  # show first nrowsxncols digits\n",
    "  plt.subplot(nrows,ncols,i+1)  # i+1 is position of subplot in nrows x ncols table\n",
    "  # show bitmap, interpret 0 as white and 255 as black (grayvalues)\n",
    "  plt.imshow(incorrect_predicted_images[i].reshape(28,28), cmap=plt.cm.gray_r)\n",
    "  plt.title(f'p: {predicted_digits[i]}; e: {expected_digits[i]}')\n",
    "  plt.xticks([])   # no ticks on x axis\n",
    "  plt.yticks([])   # not ticks on y axis"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
