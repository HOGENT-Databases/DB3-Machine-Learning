{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Deployment\n",
    "In the previous chapters we focussed on creating predicton models. Jupyter notebooks are great in data exploration, transformation and cleaning and in model tuning and evaluation. However, once you are fine with your model is time to use is in practice. Therefore we save the model to a file so we can use it over and over again.  We illustrate this using the titanic ensemble case. \n",
    "\n",
    "We first build the model. This typically has to be done only once or has to be repeated to improve the model as new data comes in or old data becomes outdated. We then save this model to a file. \n",
    "\n",
    "We then write a function that takes the features of a single passenger as parameters. That function then uses the model to guess wether or not that passenger has survived.  In a production environment that function is used together with the saved model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('lr', LogisticRegression(solver='newton-cg')),\n",
       "                             ('rf100', RandomForestClassifier()),\n",
       "                             ('rf150',\n",
       "                              RandomForestClassifier(n_estimators=150)),\n",
       "                             ('rf200',\n",
       "                              RandomForestClassifier(n_estimators=200)),\n",
       "                             ('rf250',\n",
       "                              RandomForestClassifier(n_estimators=250)),\n",
       "                             ('gnb', GaussianNB())],\n",
       "                 voting='soft')"
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "# we first build the model. \n",
    "import pandas as pd\n",
    "url = 'https://raw.githubusercontent.com/HOGENT-Databases/DB3-Workshops/master/data/titanic.csv'\n",
    "titanic = pd.read_csv(url)\n",
    "titanic = titanic.drop(['PassengerId','Name','Ticket','Fare','Cabin','Embarked'],axis=1)\n",
    "titanic = titanic.dropna()\n",
    "titanic = pd.get_dummies(titanic, columns=[\"Sex\"], prefix=[\"Sex\"])\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = titanic.drop('Survived',axis=1)\n",
    "y = titanic['Survived']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.30)\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "\n",
    "lr = LogisticRegression(solver='newton-cg')\n",
    "rf100 = RandomForestClassifier(n_estimators=100) \n",
    "rf150 = RandomForestClassifier(n_estimators=150) \n",
    "rf200 = RandomForestClassifier(n_estimators=200) \n",
    "rf250 = RandomForestClassifier(n_estimators=250) \n",
    "gnb =  GaussianNB()\n",
    "\n",
    "model = VotingClassifier(estimators=[('lr', lr), ('rf100', rf100),('rf150', rf150), ('rf200', rf200), \n",
    "                                     ('rf250', rf250), ('gnb', gnb)], voting='soft')\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-9e493e4f06db>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# see https://scikit-learn.org/stable/modules/model_persistence.html\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/content/gdrive'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mjoblib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdump\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "# we now save the model to a file\n",
    "# see https://scikit-learn.org/stable/modules/model_persistence.html\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')\n",
    "from joblib import dump\n",
    "dump(model, '/content/gdrive/My Drive/survival_prediction_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1.0)\n",
      "(0, 0.93)\n"
     ]
    }
   ],
   "source": [
    "# We will now use this model to guess wether or not an unseen passenger (one that has not been used to build the model)\n",
    "# has survived or not. \n",
    "\n",
    "def PredictSurvival(model,Pclass,Sex,Age,SibSp,Parch):\n",
    "    import pandas as pd\n",
    "    passenger=pd.DataFrame(columns=['Pclass','Sex','Age','SibSp','Parch'])\n",
    "\n",
    "    new_passenger = {'Pclass':Pclass,\n",
    "                     'Sex':Sex,\n",
    "                     'Age':Age,\n",
    "                     'SibSp':SibSp,\n",
    "                     'Parch':Parch}\n",
    "    \n",
    "    passenger = passenger.append(new_passenger,ignore_index=True)\n",
    "\n",
    "    if Sex == 'male':\n",
    "        passenger['Sex_male'] = 1\n",
    "        passenger['Sex_female'] = 0\n",
    "    else:\n",
    "        passenger['Sex_male'] = 0\n",
    "        passenger['Sex_female'] = 1        \n",
    "    passenger.drop(columns=['Sex'],axis=1,inplace=True)\n",
    "\n",
    "    # we can't use pd.get_dummies here because not all values (male,female) are available\n",
    "    # for a single customer\n",
    "    \n",
    "    survived = model.predict(passenger)\n",
    "    \n",
    "    # most sklearn algorithms also offer a predict_proba method that returns an array of \n",
    "    # probabilities per class:\n",
    "    survived_proba = model.predict_proba(passenger)\n",
    "    return survived[0],survived_proba[0].max()\n",
    "\n",
    "\n",
    "from joblib import load\n",
    "model = load('/content/gdrive/My Drive/survival_prediction_model.joblib')\n",
    "\n",
    "survived = PredictSurvival(model,Pclass=3,Sex='male',Age=40,SibSp=0,Parch=0)\n",
    "\n",
    "print(survived)\n",
    "\n",
    "survived = PredictSurvival(model,Pclass=1,Sex='female',Age=27,SibSp=0,Parch=0)\n",
    "\n",
    "print(survived)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.6 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "df9c17bba61801c11c8dda0a8ec0e06905822b892c6acee55d8adf7b70dc3da4"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}