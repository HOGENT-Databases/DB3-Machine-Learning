{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Estimating the predictive accuracy of a classifier\n",
    "- **predictive accuracy of a classifier** = the proportion of a set of unseen instances that it correctly classifies\n",
    "- Estimates by measuring its accuracy for a sample of data not used when it was generated\n",
    "- The available data is split into two parts: a _training set_ and a _test set_. \n",
    "- The training set is used to construct a classifier (decision tree, naïve bayes, etc.). \n",
    "- The classifier is then used to predict the classification for the instances in the test set. \n",
    "- If the test set contains N instances of which C are correctly classified the predictive accuracy of the classifier for the test set is p = C/N. \n",
    "- This can be used as an estimate of its performance on any unseen dataset.\n",
    "![](images/train_test_split.png)\n",
    "source: (Bramer, 2016)  \n",
    "  \n",
    "    \n",
    "- A random division into two parts in proportions such as 1:1, 2:1, 70:30 or 60:40 is customary (the largest part is the training set). \n",
    "- Obviously, the larger the proportion of the training set, the better the model, but the worse the correctness of the calculated accuracy and vice versa. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Other estimators for the predictive accuracy\n",
    "\n",
    "- The above method is not always sufficient\n",
    "- Suppose you want to predict if a person has cancer based on some features like tumor size, tumor shape and age. \n",
    "- If your test set is a subset of the complete population we know that only a very small subset of the people (fortunately) \n",
    "really have cancer. \n",
    "- So if you always predict “no cancer” you will probably have an accuracy of over 95%, but are still missing all the persons who have cancer. \n",
    "- Your model should at least be better than this “guessing” method.  \n",
    "  \n",
    "Solution: breakdown the classifier's performance:\n",
    "- how frequently instances of class X were correctly classified as class X or misclassified as some other class\n",
    "- visualized by **confusion matrix**\n",
    "- e.g. (very accurate) e-mail classification model wich classifies e-mails (from mailing lists) into 4 categories: ADS, ICT, JOB and NEWS    \n",
    "  \n",
    "![](images/confusion_matrix.png)\n",
    "\n",
    "- For binary classifiers (like cancer/no cancer) the confusion matrix looks like this:  \n",
    "  \n",
    "![](images/confusion_matrix_tp_tn.png)  \n",
    "  \n",
    "In medicine false positives are considered as Type I errors and false negatives as  Type II errors:  \n",
    "  \n",
    "![](images/pregnant.png) \n",
    "  \n",
    "Several measures are linked to this observation for binary classifiers: \n",
    "  \n",
    "- _false positive rate_ : the proportion of all negatives that still yield positive test outcomes  \n",
    "    \n",
    "  <p align=\"center\">FP-rate = $\\frac{FP}{FP + TN}$</p>\n",
    "  \n",
    "  \n",
    "- _false negative rate_ : the proportion of all positives which yield negative test outcomes  \n",
    "    \n",
    "  <p align=\"center\">FN-rate = $\\frac{FN}{TP + FN}$</p>\n",
    "   \n",
    "Obviously, in the cancer case we have to avoid false negatives, because in that case we are missing people really having cancer, so the false negative rate is an important measure. \n",
    "  \n",
    "- _precision_ : the proportion of all samples that were predicted as positive which are really positive\n",
    "    \n",
    "  <p align=\"center\">$P = \\frac{TP}{TP + FP}$</p>  \n",
    "   \n",
    "   \n",
    "- _recall_ : the proportion of all positives which are correctly predicted\n",
    "    \n",
    "  <p align=\"center\">$R = \\frac{TP}{TP + FN}$</p>  \n",
    "  \n",
    "  \n",
    "- For a classifier that predicts all samples correct both precision and recall are equal to 1. For an algorithm that always predicts 1 the recall = 1 (because there are no false negatives), but the precision only equals the positive rate in the dataset because you can have a large number of false positives. Therefore it's important to have a single measure that combines both precision and recall, the _F-score_. \n",
    "    \n",
    "  <p align=\"center\">$F = 2\\frac{P \\cdot R}{P + R}$</p>   \n",
    "  \n",
    "   \n",
    " - Finally, we can define the _accuracy score_ we have seen above as:  \n",
    "     \n",
    "  <p align=\"center\">$\\alpha = \\frac{TP + TN}{TP + TN + FP + FN}$</p>\n",
    " \n",
    "   \n",
    "  \n",
    "### Exercise\n",
    "  \n",
    "  \n",
    "In een artikel in de Gazet van Antwerpen van 27 juli 2017 stond het volgende te lezen.   \n",
    "  \n",
    "Bij een NIPT-test wordt bloed afgenomen (van een zwangere vrouw), om te weten te komen of een ongeboren kind het Syndroom van Down heeft. Na twee weken zou je dan 99 procent zeker weten of je kind aan het syndroom lijdt of niet. Maar dat klopt niet, zeggen onderzoekers van de Gentse Universiteit. Het is helemaal niet zeker dat je kind het syndroom heeft, ook al geeft de test dat aan.  \n",
    "  \n",
    "“Eigenlijk is dat zeer afhankelijk van de risico’s die er op voorhand zijn. Bij jonge vrouwen die geen afwijkingen hebben op hun echografie, kan de kans op toch een gezond kind tot vijftig procent zijn”, zegt Heidi Mertes, onderzoekster van de Universiteit Gent.  \n",
    "  \n",
    "Volgens nieuwe berekeningen van de UGent heeft een gemiddelde vrouw van 40 jaar 93 procent kans dat haar kind ook echt Down heeft na een afwijkende NIPT-test. Bij een vrouw van 35 is dat 79 procent, op 30 jaar 61 procent en op 25 jaar nog maar 51 procent.  \n",
    "  \n",
    "\n",
    "Welke van onderstaande uitspraken is dan waar?\n",
    "  \n",
    "   \n",
    "1.\tDe true positive rate is 99%\n",
    "1.\tBij een vrouw van 40 is de true negative rate 93%\n",
    "1.\tBij een vrouw van 35 is de precisie 79%\n",
    "1.\tBij alle vrouwen is de true negative rate 50%"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
